---
title: "Homework 5"
author: "Juan Cambeiro"
date: "2022-11-16"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(readxl)
library(ggridges)
library(patchwork)
library(readr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


## Problem 2

First, I will import and clean the homicide data that was gathered by The Washington Post and describe the raw data.
```{r}
homicide =
  read_csv("data/homicide-data.csv") %>%
  janitor::clean_names()
```

**Description of raw data**: This homicides dataset collected by The Washington Post includes data on `r nrow(homicide)` in 50 of the largest American cities. The dataset contains `r ncol(homicide)` variables, including: the report date of the homicide (`report_date`), the victim's first and last name (`victim_first`, `victim_last`), key demographics of the victim (`victim_race`, `victim_age`, `victim_sex`), the location (`city`, `state`, `lat`, `lon`), and the status of the case (`disposition`). 


Next, I will tidy the data by using `mutate` to ensure appropriate data types and to make a `city_state` variable. 
```{r}
homicide_tidy = homicide %>%
  mutate(city_state = as.factor(str_c(city, state, sep = ", ")), 
         reported_date = as.Date(as.character(reported_date),"%Y%m%d"), 
         victim_age = as.numeric(victim_age), 
         victim_sex = as.factor(victim_sex),
         victim_race = as.factor(victim_race), 
         city = as.factor(city),
         state = as.factor(state)) 
```


Now, I will use `group by` and `summarize` to  obtain the total number of homicides and number of unsolved homicides by city and display these totals by city using `kable`.
```{r}
summary_by_city = homicide_tidy %>% 
  group_by(city_state) %>% 
  summarize(homicides_total = n(), 
            unsolved_total = sum(disposition == c("Closed without arrest", "Open/No arrest")))
knitr::kable(summary_by_city)
```


Next, I run `prop.test` in my dataset `summary_by_city` to estimate the proportion of homicides that are unsolved in Baltimore, MD, along with the corresponding CI.
```{r}
baltimore = summary_by_city %>%
  filter(city_state == "Baltimore, MD") 
baltimore_test = prop.test(
  x = baltimore[["unsolved_total"]],
  n = baltimore[["homicides_total"]]) %>%
  broom::tidy() %>%
  select(estimate, conf.low, conf.high)
knitr::kable(baltimore_test)
```
I find an estimate of 0.32 (95% CI: 0.30, 0.34) for the proportion of of homicides that are unsolved in Baltimore, MD.


Now, I run `prop.test` in my dataset `summary_by_city` for each of the cities in my dataset to estimate the proportion of homicides that are unsolved in each, along with corresponding CIs. I use `purrr:map2` to apply `prop.test` to each of the cities. I display the estimates and CIs for each city using `kable`.
```{r}
cities_tests =
  summary_by_city %>%
  mutate(p_test = map2(unsolved_total, homicides_total, ~ prop.test(.x, .y) %>%
  broom::tidy())) %>% 
  unnest() %>%
  select(city_state, estimate, conf.low, conf.high)
knitr::kable(cities_tests)
```


Next, I create a plot that shows the estimates and CIs of the proportion of unsolved homicides for each city. I use `geom_errorbar` to add the upper and lower limits. The cities are ordered according to proportion of unsolved homicides.
```{r}
cities_tests %>%
  mutate(city_state = fct_reorder(city_state, estimate)) %>%
  ggplot(aes(x = estimate, y = city_state)) + geom_point() + geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + 
  labs(
    title = "Proportion of unsolved homicides in the 50 largest U.S. cities",
    x = "Proportion of unsolved homicides",
    y = "City"
  )
```



## Problem 3

Here I want to conduct a simulation to explore power in a one-sample t-test. I want to fix the design elements as n = 30, σ = 5. I set μ = 0. 

I begin by generating 5000 datasets that follow x∼Normal[0,5] with n = 30. 
```{r}
output = vector("list", 5000)
for (i in 1:5000) {
  output[[i]] = rnorm(n = 30, sd = 5, mean = 0)
  }
```

Next, I do a t-test and obtain the estimate and p-value.
```{r}
t_test = function(x) {
  t_test_results = t.test(x) %>% 
  broom::tidy() %>%
  select(estimate, p.value)}
```
